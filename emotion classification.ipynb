{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 神經網路\n",
    "\n",
    "情感分類：\n",
    "1. 核心情緒: 最直接的感受情緒，如喜怒哀樂等等\n",
    "2. 抑制情緒: 壓抑對情緒的感受，如焦慮、內疚後悔、慚愧\n",
    "3. 防禦情緒: 逃避對情緒的感受，如拖延、成癮、疏離\n",
    "\n",
    "\n",
    "<img src = \"/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/tri_emotions_pic.jpeg\" height=\"700\" width=\"500\">\n",
    "\n",
    "應用：分析以上三種情緒可以幫助了解個體的情緒變化，透過辨別逃避與壓抑的情感（抑制情緒、防禦情緒）才有辦法掌握掌握自己的真實情緒（核心情緒）。\n",
    "\\\n",
    "相關應用或許可以包涵分析青少年在網路上的貼文內容，並在他們表現出抑制或防禦情緒時適時給予協助。\n",
    "\n",
    "語料蒐集：dcard心情版貼文、ptt sad版\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "核心情緒文本數 178\n",
      "抑制情緒文本數 133\n",
      "防禦情緒文本數 123\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def unify_hash_symbols(pos_text):\n",
    "    return pos_text.replace('＃', '#')\n",
    "\n",
    "core_emo_path = '/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/神經網路語料/核心情緒（喜怒哀樂）.txt'\n",
    "depress_emo_path = '/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/神經網路語料/抑制情緒（慚愧、焦慮、內疚）.txt'\n",
    "defense_emo_path = '/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/神經網路語料/防禦情緒（轉移話題、開玩笑、疏離拖延、上癮.txt'\n",
    "\n",
    "core_emo_corpus = read_text_file(core_emo_path)\n",
    "depress_emo_corpus = read_text_file(depress_emo_path)\n",
    "defense_emo_corpus = read_text_file(defense_emo_path)\n",
    "\n",
    "core_emo_corpus = unify_hash_symbols(core_emo_corpus)\n",
    "depress_emo_corpus = unify_hash_symbols(depress_emo_corpus)\n",
    "defense_emo_corpus = unify_hash_symbols(defense_emo_corpus)\n",
    "\n",
    "core_texts = [text for text in core_emo_corpus.split('#') if text.strip()]\n",
    "depress_texts = [text for text in depress_emo_corpus.split('#') if text.strip()]\n",
    "defense_texts = [text for text in defense_emo_corpus.split('#') if text.strip()]\n",
    "\n",
    "num_core = len(core_texts)\n",
    "num_depress = len(depress_texts)\n",
    "num_defense = len(defense_texts)\n",
    "\n",
    "print(\"核心情緒文本數\", num_core)\n",
    "print(\"抑制情緒文本數\", num_depress)\n",
    "print(\"防禦情緒文本數\", num_defense)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟一：製作斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "2024-06-20 13:54:25.468634: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "from utilities import concatFiles, word_segmenter\n",
    "import pandas as pd \n",
    "\n",
    "core_emo, depress_emo, defense_emo = concatFiles('/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/神經網路語料')\n",
    "\n",
    "core_emo_tokens= word_segmenter (core_emo)\n",
    "depress_emo_tokens= word_segmenter (depress_emo)\n",
    "defense_emo_tokens= word_segmenter (defense_emo)\n",
    "\n",
    "core_label= [0.]*len(core_emo_tokens) #核心情緒標0\n",
    "depress_label= [1.]*len(depress_emo_tokens) #抑制情緒標1\n",
    "defense_label= [2.]*len(defense_emo_tokens) #防禦情緒標2\n",
    "\n",
    "\n",
    "all_tokens= core_emo_tokens+ depress_emo_tokens+defense_emo_tokens\n",
    "all_labels= core_label+depress_label+defense_label\n",
    "\n",
    "pd.DataFrame({'tokens':all_tokens, 'labels':all_labels}).to_csv('神經網路_斷詞.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟二：製作w2v模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "dataDF = pd.read_csv('/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/神經網路_斷詞.csv')\n",
    "labels = dataDF['labels'].values\n",
    "\n",
    "tokensLST = []\n",
    "for i in range(len(dataDF)):\n",
    "    tokensLST.append(eval(dataDF.iloc[i]['tokens']))\n",
    "\n",
    "\n",
    "w2v_model = Word2Vec(vector_size=100, window=5, min_count=1, workers=4)\n",
    "w2v_model.build_vocab(tokensLST)\n",
    "\n",
    "model_dir = '/Users/chiachenhsu/Desktop/nlp final project/project 2'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(model_dir, '神經網路_word2vec.model')\n",
    "w2v_model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟三：讀入斷詞與模型並轉成數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dataDF = pd.read_csv(\"/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/神經網路_斷詞.csv\")\n",
    "rnn_labels = rnn_dataDF['labels']\n",
    "\n",
    "tokenslist = []\n",
    "for i in range(len(dataDF)):\n",
    "    tokenslist.append(eval(dataDF.iloc[i]['tokens']))\n",
    "\n",
    "rnn_model_name = '/Users/chiachenhsu/Desktop/nlp final project/project 2/神經網路_word2vec.model'\n",
    "rnn_model = Word2Vec.load(rnn_model_name)\n",
    "\n",
    "vectorized_corpus = []\n",
    "\n",
    "for tokensTXT in tokenslist:\n",
    "    temp_vec = []\n",
    "    for token in tokensTXT:\n",
    "        if token in rnn_model.wv:\n",
    "            temp_vec.append(rnn_model.wv[token])\n",
    "    vectorized_corpus.append(temp_vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟四：RNN訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 1.1214 - precision: 0.3425 - recall: 0.0701 - f1_score: 0.3128 - accuracy: 0.3590 - val_loss: 1.1150 - val_precision: 0.2500 - val_recall: 0.0056 - val_f1_score: 0.1967 - val_accuracy: 0.3855\n",
      "Epoch 2/5\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 1.0876 - precision: 0.4286 - recall: 0.0252 - f1_score: 0.2925 - accuracy: 0.4053 - val_loss: 1.1165 - val_precision: 0.2500 - val_recall: 0.0391 - val_f1_score: 0.2130 - val_accuracy: 0.4022\n",
      "Epoch 3/5\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 1.0783 - precision: 0.4576 - recall: 0.0379 - f1_score: 0.3137 - accuracy: 0.4306 - val_loss: 1.1041 - val_precision: 0.3750 - val_recall: 0.0168 - val_f1_score: 0.2068 - val_accuracy: 0.3855\n",
      "Epoch 4/5\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 1.0542 - precision: 0.6667 - recall: 0.0337 - f1_score: 0.3228 - accuracy: 0.4460 - val_loss: 1.4448 - val_precision: 0.3593 - val_recall: 0.3352 - val_f1_score: 0.2902 - val_accuracy: 0.3575\n",
      "Epoch 5/5\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.0492 - precision: 0.5714 - recall: 0.1122 - f1_score: 0.3770 - accuracy: 0.4642 - val_loss: 1.1399 - val_precision: 0.2143 - val_recall: 0.0168 - val_f1_score: 0.3646 - val_accuracy: 0.3799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x297cdb2d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, SimpleRNN\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf \n",
    "\n",
    "num_neurons = 30\n",
    "maxlen = 300\n",
    "batch_size = 32\n",
    "embedding_dims = 100\n",
    "filters = 150 \n",
    "kernel_size = 3\n",
    "hidden_dims = 250 \n",
    "epochs = 5\n",
    "\n",
    "zero_vec = [1e-9]*embedding_dims\n",
    "rnn_X = pad_sequences(vectorized_corpus, maxlen=maxlen, dtype='float', padding='post', truncating='post', value=zero_vec)\n",
    "num_classes= 3\n",
    "rnn_y = to_categorical(all_labels, num_classes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(rnn_X, rnn_y, test_size=0.2, random_state=1)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(num_neurons, return_sequences=True, input_shape=(maxlen, embedding_dims))) \n",
    "rnn_model.add(Dropout(0.2))\n",
    "rnn_model.add(Flatten())\n",
    "rnn_model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "rnn_model.compile(optimizer=\"rmsprop\", loss='categorical_crossentropy',\n",
    "              metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n",
    "                         tf.keras.metrics.F1Score(), 'accuracy'])\n",
    "\n",
    "rnn_model.fit(X_train, y_train, batch_size=batch_size,\n",
    "          epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練集評估指標\n",
    "|Precision|Recal|F1 score|Accuracy|\n",
    "|---|---|---|---|\n",
    "|0.5714|0.1122|0.3770|0.4642|\n",
    "\n",
    "測試集評估指標\n",
    "|Precision|Recal|F1 score|Accuracy|\n",
    "|---|---|---|---|\n",
    "|0.2143|0.0168|0.3646|0.3799|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評估指標的表現皆不好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟五：預測新語料\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 3/3 [00:00<00:00, 5199.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "[[0.28247163 0.3778495  0.33967882]\n",
      " [0.33318555 0.38945654 0.2773579 ]\n",
      " [0.3980269  0.25898156 0.34299153]]\n",
      "\n",
      "要預測的貼文為：\n",
      " \n",
      "前幾天心情很不好，於是在凌晨四點到wootalk找人聊天，遇到了一個很好很好的人，他開導了我很多，告訴我一定要活著要請他吃牛排，後來我們加了賴，聊了很久，我還以為找到了知己（我知道自己想太多），不過還是謝謝這個陌生人，如果你有看到，我想說，謝謝你在我最黑暗的時候拉住了我，雖然也許沒有交集了，也不知道為什麼你突然沒找我了，也許是我長得不好看？哈哈哈哈\n",
      "但我卻有點動心了⋯⋯\n",
      "相信我可以很快走出來的\n",
      "\n",
      "這則貼文表現的情緒為：抑制情緒\n",
      "\n",
      "要預測的貼文為：\n",
      "\n",
      "最近發現自己常常覺得心情低落、心裡莫名煩躁 然後什麼事都不想做\n",
      "要脫離這種感覺只有看綜藝或追劇煩躁感才比較容易消失\n",
      "如果說要出去外面逛逛也不好說\n",
      "最近因為被騙錢 所以想報復性花錢也只能想想（就算沒被騙也不太可能）\n",
      "台北的物價大家也知道 就算什麼都不買只吃東西也不便宜\n",
      "我是屬於不好的情緒不太會表現出來 都自己默默消化的那種 所以外人眼裡我幾乎都是很正向樂觀\n",
      "想問如果有遇到這種心情的都是怎麼調適\n",
      "請留言的各位手下留情\n",
      "太多一言不合就吵的有點恐怖\n",
      "\n",
      "這則貼文表現的情緒為：抑制情緒\n",
      "\n",
      "要預測的貼文為：\n",
      "心情好糟\n",
      "發瘋\n",
      "找不到適合求助\n",
      "每次總是吃虧\n",
      "越來越恨這世界\n",
      "沒人在乎..\n",
      "\n",
      "這則貼文表現的情緒為：核心情緒\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utilities import segmentAndW2V\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "\n",
    "#預期結果應為核心情緒，和測試結果不一樣\n",
    "newEmotion1= ''' \n",
    "前幾天心情很不好，於是在凌晨四點到wootalk找人聊天，遇到了一個很好很好的人，他開導了我很多，告訴我一定要活著要請他吃牛排，後來我們加了賴，聊了很久，我還以為找到了知己（我知道自己想太多），不過還是謝謝這個陌生人，如果你有看到，我想說，謝謝你在我最黑暗的時候拉住了我，雖然也許沒有交集了，也不知道為什麼你突然沒找我了，也許是我長得不好看？哈哈哈哈\n",
    "但我卻有點動心了⋯⋯\n",
    "相信我可以很快走出來的'''\n",
    "\n",
    "#預期結果應為抑制情緒，和測試結果一樣\n",
    "newEmotion2 = '''\n",
    "最近發現自己常常覺得心情低落、心裡莫名煩躁 然後什麼事都不想做\n",
    "要脫離這種感覺只有看綜藝或追劇煩躁感才比較容易消失\n",
    "如果說要出去外面逛逛也不好說\n",
    "最近因為被騙錢 所以想報復性花錢也只能想想（就算沒被騙也不太可能）\n",
    "台北的物價大家也知道 就算什麼都不買只吃東西也不便宜\n",
    "我是屬於不好的情緒不太會表現出來 都自己默默消化的那種 所以外人眼裡我幾乎都是很正向樂觀\n",
    "想問如果有遇到這種心情的都是怎麼調適\n",
    "請留言的各位手下留情\n",
    "太多一言不合就吵的有點恐怖'''\n",
    "\n",
    "#預期結果應為防禦情緒，和測試結果一樣\n",
    "newEmotion3 = '''心情好糟\n",
    "發瘋\n",
    "找不到適合求助\n",
    "每次總是吃虧\n",
    "越來越恨這世界\n",
    "沒人在乎..'''\n",
    "\n",
    "\n",
    "newEmotions = [newEmotion1, newEmotion2, newEmotion3]\n",
    "newEmotionsMAT = segmentAndW2V(newEmotions)\n",
    "\n",
    "\n",
    "preds = rnn_model.predict(newEmotionsMAT)\n",
    "print(preds)\n",
    "print()\n",
    "\n",
    "categories = {0: '核心情緒', 1: '抑制情緒', 2: '防禦情緒'}\n",
    "\n",
    "for i, txt in enumerate(newEmotions):\n",
    "    print(f\"要預測的貼文為：\\n{txt}\\n\")\n",
    "    \n",
    "    pred_label = preds[i].argmax()\n",
    "    print(f\"這則貼文表現的情緒為：{categories[pred_label]}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 綜合討論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一則貼文：分類錯誤。作者提到相信自己很快釋懷，是核心情緒的定義，但是卻誤判成抑制情緒。\n",
    "\\\n",
    "\\\n",
    "第二則貼文：分類正確。文本提及低落與煩躁，和抑制情緒中焦慮的特徵類似。\n",
    "\\\n",
    "\\\n",
    "第三則貼文：分類錯誤。原文提到提到「找不到求助」、「沒人在乎」，為防禦情緒的疏離態度展現，但是卻誤判成核心情緒。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 後續修改\n",
    "由於評估指標數值欠佳，將進行以下修改看能否提升分類結果\n",
    "\n",
    "1. 修改一：自製的w2v模型因語料太少，表現不好，所以改用課堂使用的ccu_w2v_model\n",
    "2. 修改二：修改超參數與調整dropout層，提升評估指標表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改一：斷詞、導入ccu_w2v_model模型、將斷詞轉成數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dataDF = pd.read_csv(\"/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/神經網路_斷詞.csv\")\n",
    "rnn_labels = rnn_dataDF['labels']\n",
    "\n",
    "tokenslist = []\n",
    "for i in range(len(dataDF)):\n",
    "    tokenslist.append(eval(dataDF.iloc[i]['tokens']))\n",
    "\n",
    "ccu_model_name= '/Users/chiachenhsu/Desktop/nlp final project_許家禎/project 2/ccu_w2v_model04'\n",
    "ccu_model = Word2Vec.load(ccu_model_name)\n",
    "\n",
    "vectorized_corpus = []\n",
    "\n",
    "for tokensTXT in tokenslist:\n",
    "    temp_vec = []\n",
    "    for token in tokensTXT:\n",
    "        if token in ccu_model.wv:\n",
    "            temp_vec.append(ccu_model.wv[token])\n",
    "    vectorized_corpus.append(temp_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改二：修改超參數與調整dropout層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "23/23 [==============================] - 3s 87ms/step - loss: 1.3500 - precision_2: 0.3849 - recall_2: 0.2791 - f1_score: 0.3744 - accuracy: 0.3913 - val_loss: 1.7713 - val_precision_2: 0.3860 - val_recall_2: 0.3687 - val_f1_score: 0.3017 - val_accuracy: 0.3799\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 1.1249 - precision_2: 0.5529 - recall_2: 0.4544 - f1_score: 0.4921 - accuracy: 0.5077 - val_loss: 1.4377 - val_precision_2: 0.2909 - val_recall_2: 0.2682 - val_f1_score: 0.2848 - val_accuracy: 0.2849\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.8787 - precision_2: 0.6470 - recall_2: 0.5063 - f1_score: 0.5848 - accuracy: 0.5975 - val_loss: 1.4639 - val_precision_2: 0.3312 - val_recall_2: 0.2849 - val_f1_score: 0.3289 - val_accuracy: 0.3408\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.8393 - precision_2: 0.6490 - recall_2: 0.5498 - f1_score: 0.6006 - accuracy: 0.6045 - val_loss: 1.2909 - val_precision_2: 0.4387 - val_recall_2: 0.3799 - val_f1_score: 0.3497 - val_accuracy: 0.4246\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.7292 - precision_2: 0.7556 - recall_2: 0.5680 - f1_score: 0.6411 - accuracy: 0.6508 - val_loss: 1.3031 - val_precision_2: 0.4174 - val_recall_2: 0.2682 - val_f1_score: 0.3784 - val_accuracy: 0.4358\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.7407 - precision_2: 0.7213 - recall_2: 0.5989 - f1_score: 0.6631 - accuracy: 0.6718 - val_loss: 1.4693 - val_precision_2: 0.3438 - val_recall_2: 0.3073 - val_f1_score: 0.3046 - val_accuracy: 0.3240\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.7407 - precision_2: 0.7128 - recall_2: 0.5919 - f1_score: 0.6570 - accuracy: 0.6648 - val_loss: 1.3111 - val_precision_2: 0.4640 - val_recall_2: 0.3240 - val_f1_score: 0.3758 - val_accuracy: 0.4413\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.6614 - precision_2: 0.7792 - recall_2: 0.5989 - f1_score: 0.6660 - accuracy: 0.6746 - val_loss: 1.3368 - val_precision_2: 0.3902 - val_recall_2: 0.1788 - val_f1_score: 0.3411 - val_accuracy: 0.3408\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6915 - precision_2: 0.7155 - recall_2: 0.5820 - f1_score: 0.6326 - accuracy: 0.6381 - val_loss: 1.3652 - val_precision_2: 0.4658 - val_recall_2: 0.4190 - val_f1_score: 0.3675 - val_accuracy: 0.4358\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6343 - precision_2: 0.7880 - recall_2: 0.6101 - f1_score: 0.6759 - accuracy: 0.6844 - val_loss: 1.3394 - val_precision_2: 0.3953 - val_recall_2: 0.1899 - val_f1_score: 0.3289 - val_accuracy: 0.3296\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6364 - precision_2: 0.7587 - recall_2: 0.5820 - f1_score: 0.6487 - accuracy: 0.6550 - val_loss: 1.3539 - val_precision_2: 0.4096 - val_recall_2: 0.1899 - val_f1_score: 0.3293 - val_accuracy: 0.3296\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6223 - precision_2: 0.8224 - recall_2: 0.5652 - f1_score: 0.6502 - accuracy: 0.6564 - val_loss: 1.3360 - val_precision_2: 0.4531 - val_recall_2: 0.3240 - val_f1_score: 0.3502 - val_accuracy: 0.4246\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5960 - precision_2: 0.8135 - recall_2: 0.5933 - f1_score: 0.6912 - accuracy: 0.6985 - val_loss: 1.3650 - val_precision_2: 0.4194 - val_recall_2: 0.2905 - val_f1_score: 0.3566 - val_accuracy: 0.4190\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6070 - precision_2: 0.8246 - recall_2: 0.5736 - f1_score: 0.6762 - accuracy: 0.6816 - val_loss: 1.4454 - val_precision_2: 0.4424 - val_recall_2: 0.4078 - val_f1_score: 0.3514 - val_accuracy: 0.4190\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6111 - precision_2: 0.7977 - recall_2: 0.5806 - f1_score: 0.6751 - accuracy: 0.6802 - val_loss: 1.3577 - val_precision_2: 0.4651 - val_recall_2: 0.2235 - val_f1_score: 0.3624 - val_accuracy: 0.3743\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5828 - precision_2: 0.8780 - recall_2: 0.5147 - f1_score: 0.6569 - accuracy: 0.6634 - val_loss: 1.3316 - val_precision_2: 0.4534 - val_recall_2: 0.4078 - val_f1_score: 0.3666 - val_accuracy: 0.4358\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5866 - precision_2: 0.8463 - recall_2: 0.5484 - f1_score: 0.6630 - accuracy: 0.6718 - val_loss: 1.3376 - val_precision_2: 0.4651 - val_recall_2: 0.3352 - val_f1_score: 0.3501 - val_accuracy: 0.4246\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5895 - precision_2: 0.8202 - recall_2: 0.5820 - f1_score: 0.6731 - accuracy: 0.6830 - val_loss: 1.3607 - val_precision_2: 0.3956 - val_recall_2: 0.2011 - val_f1_score: 0.3427 - val_accuracy: 0.3575\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.5836 - precision_2: 0.8465 - recall_2: 0.5722 - f1_score: 0.6842 - accuracy: 0.6900 - val_loss: 1.4460 - val_precision_2: 0.3788 - val_recall_2: 0.2793 - val_f1_score: 0.3679 - val_accuracy: 0.3799\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6337 - precision_2: 0.7719 - recall_2: 0.6171 - f1_score: 0.6704 - accuracy: 0.6802 - val_loss: 1.4193 - val_precision_2: 0.3622 - val_recall_2: 0.2570 - val_f1_score: 0.3198 - val_accuracy: 0.3296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29c8a9650>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, SimpleRNN\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf \n",
    "\n",
    "num_neurons = 50 #增加神經元數\n",
    "maxlen = 300\n",
    "batch_size = 32\n",
    "embedding_dims = 300\n",
    "filters = 200 \n",
    "kernel_size = 3\n",
    "hidden_dims = 250 \n",
    "epochs = 20 #提高迭代次數\n",
    "\n",
    "zero_vec = [1e-9]*embedding_dims\n",
    "rnn_X = pad_sequences(vectorized_corpus, maxlen=maxlen, dtype='float', padding='post', truncating='post', value=zero_vec)\n",
    "num_classes= 3\n",
    "rnn_y = to_categorical(all_labels, num_classes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(rnn_X, rnn_y, test_size=0.2, random_state=1)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(num_neurons, return_sequences=True, input_shape=(maxlen, embedding_dims))) \n",
    "rnn_model.add(SimpleRNN(num_neurons, return_sequences=True))  \n",
    "rnn_model.add(SimpleRNN(num_neurons, return_sequences=True))  #增加層數\n",
    "rnn_model.add(Dropout(0.35)) #提高dropout\n",
    "rnn_model.add(Flatten())\n",
    "rnn_model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "rnn_model.compile(optimizer=\"adam\", loss='categorical_crossentropy', #把優化器從rmsprop改成adam\n",
    "              metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n",
    "                         tf.keras.metrics.F1Score(), 'accuracy'])\n",
    "\n",
    "rnn_model.fit(X_train, y_train, batch_size=batch_size,\n",
    "          epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改前後比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練集\n",
    "|評估指標|Precision|Recal|F1 score|Accuracy|\n",
    "|---|---|---|---|---|\n",
    "|修改前|0.5714|0.1122|0.3770|0.4642|\n",
    "|修改後|0.7719|0.6171|0.6704|0.6802|\n",
    "\n",
    "測試集\n",
    "|評估指標|Precision|Recal|F1 score|Accuracy|\n",
    "|---|---|---|---|---|\n",
    "|修改前|0.2143|0.0168|0.3646|0.3799|\n",
    "|修改後|0.3622|0.2570|0.3198|0.3296|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結語"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評估指標表現整體而言仍偏低，但透過以下修改仍可以微幅提升分類的表現。包含：\n",
    "1. 改用語料數較龐大的w2v模型\n",
    "2. 增加神經元數: 原30增至50\n",
    "3. 增加迭代次數: 原5次增至20次\n",
    "4. 提高dropout:原0.2提高到0.35\n",
    "5. 增加神經網路層數: 原1層增至3層\n",
    "6. 不同優化器：原rmsprop改成adam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
